#!/usr/bin/env python3
"""
DeepSeek-OCR Web Service - å¢å¼ºç‰ˆ
åŸºäº transformers çš„ç¨³å®šå®ç°ï¼ˆæ›¿ä»£ vLLMï¼‰
é›†æˆäº† Find å’Œ Freeform åŠŸèƒ½
"""
import os
import re
import tempfile
import shutil
import io
import base64
import time
from typing import Optional, List, Dict, Any
from contextlib import asynccontextmanager
from pathlib import Path

from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.responses import JSONResponse, HTMLResponse
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image, ImageOps
import torch
from transformers import AutoModel, AutoTokenizer
import uvicorn
import fitz  # PyMuPDF

# å…¨å±€å˜é‡
model = None
tokenizer = None
MODEL_PATH = 'deepseek-ai/DeepSeek-OCR'
MODEL_SOURCE = None  # è®°å½•å®é™…ä½¿ç”¨çš„æ¨¡å‹æº

# æ¨¡å‹æºé…ç½®
MODEL_SOURCES = {
    'huggingface': 'deepseek-ai/DeepSeek-OCR',
    'modelscope': 'deepseek-ai/DeepSeek-OCR'
}

# è‡ªå®šä¹‰è¶…æ—¶å¼‚å¸¸
class ModelLoadTimeoutError(Exception):
    """æ¨¡å‹åŠ è½½è¶…æ—¶å¼‚å¸¸"""
    pass

def load_model_from_source(source_name: str, model_path: str, timeout: int = 300) -> tuple:
    """
    ä»æŒ‡å®šæºåŠ è½½æ¨¡å‹
    
    Args:
        source_name: æ¨¡å‹æºåç§° ('huggingface' æˆ– 'modelscope')
        model_path: æ¨¡å‹è·¯å¾„
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    
    Returns:
        (model, tokenizer) å…ƒç»„
    
    Raises:
        TimeoutError: åŠ è½½è¶…æ—¶
        Exception: å…¶ä»–åŠ è½½é”™è¯¯
    """
    import requests
    from requests.exceptions import Timeout as RequestsTimeout, ConnectionError as RequestsConnectionError
    
    print(f"ğŸ“¦ å°è¯•ä» {source_name.upper()} åŠ è½½æ¨¡å‹: {model_path}")
    
    if source_name == 'modelscope':
        try:
            from modelscope import snapshot_download
            import os
            
            # ä½¿ç”¨ ModelScope ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ç¼“å­˜
            print(f"ğŸ“¥ æ­£åœ¨ä» ModelScope ä¸‹è½½æ¨¡å‹...")
            print(f"   æ¨¡å‹è·¯å¾„: {model_path}")
            print(f"   ç¼“å­˜ç›®å½•: {os.environ.get('MODELSCOPE_CACHE', os.path.expanduser('~/.cache/modelscope'))}")
            
            local_model_path = snapshot_download(
                model_id=model_path,
                cache_dir=os.environ.get('MODELSCOPE_CACHE', os.path.expanduser('~/.cache/modelscope')),
                revision='master'
            )
            print(f"âœ… ModelScope æ¨¡å‹å·²ä¸‹è½½åˆ°: {local_model_path}")
            
            # ä»æœ¬åœ°è·¯å¾„åŠ è½½
            print(f"ğŸ“¦ æ­£åœ¨ä»æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹...")
            tokenizer = AutoTokenizer.from_pretrained(
                local_model_path,
                trust_remote_code=True,
            )
            
            model = AutoModel.from_pretrained(
                local_model_path,
                trust_remote_code=True,
                use_safetensors=True,
                attn_implementation="eager",
                torch_dtype=torch.bfloat16,
            ).eval().to("cuda")
            
            return model, tokenizer
            
        except Exception as e:
            print(f"âŒ ModelScope åŠ è½½å¤±è´¥: {e}")
            import traceback
            print(f"   é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            raise
    else:
        # HuggingFace åŠ è½½
        try:
            # è®¾ç½® requests è¶…æ—¶ï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡ï¼‰
            # transformers å†…éƒ¨ä½¿ç”¨ requestsï¼Œå¯ä»¥é€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡æ§åˆ¶è¶…æ—¶
            os.environ['HF_HUB_DOWNLOAD_TIMEOUT'] = str(timeout)
            
            print(f"ğŸ“¥ æ­£åœ¨ä» HuggingFace ä¸‹è½½æ¨¡å‹...")
            print(f"   è¶…æ—¶è®¾ç½®: {timeout} ç§’")
            
            # å°è¯•åŠ è½½ tokenizer
            tokenizer = AutoTokenizer.from_pretrained(
                model_path,
                trust_remote_code=True,
            )
            print(f"âœ… Tokenizer åŠ è½½æˆåŠŸ")
            
            # å°è¯•åŠ è½½æ¨¡å‹
            model = AutoModel.from_pretrained(
                model_path,
                trust_remote_code=True,
                use_safetensors=True,
                attn_implementation="eager",
                torch_dtype=torch.bfloat16,
            ).eval().to("cuda")
            print(f"âœ… Model åŠ è½½æˆåŠŸ")
            
            return model, tokenizer
            
        except (RequestsTimeout, RequestsConnectionError) as e:
            print(f"â±ï¸ HuggingFace ç½‘ç»œè¿æ¥è¶…æ—¶æˆ–å¤±è´¥: {e}")
            raise ModelLoadTimeoutError(f"HuggingFace è¿æ¥è¶…æ—¶ ({timeout} ç§’)")
        except Exception as e:
            error_msg = str(e).lower()
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œç›¸å…³é”™è¯¯
            if any(keyword in error_msg for keyword in ['timeout', 'connection', 'network', 'unreachable', 'refused']):
                print(f"â±ï¸ HuggingFace ç½‘ç»œé”™è¯¯: {e}")
                raise ModelLoadTimeoutError(f"HuggingFace ç½‘ç»œé”™è¯¯: {e}")
            else:
                print(f"âŒ HuggingFace åŠ è½½å¤±è´¥: {e}")
                import traceback
                print(f"   é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                raise

@asynccontextmanager
async def lifespan(app: FastAPI):
    """æ¨¡å‹åŠ è½½ç”Ÿå‘½å‘¨æœŸ - æ”¯æŒè‡ªåŠ¨åˆ‡æ¢æ¨¡å‹æº"""
    global model, tokenizer, MODEL_SOURCE
    
    print("="*50)
    print("ğŸš€ DeepSeek-OCR å¢å¼ºç‰ˆå¯åŠ¨ä¸­...")
    print("="*50)
    
    model_loaded = False
    last_error = None
    
    # å°è¯•ä» HuggingFace åŠ è½½
    for source_name in ['huggingface', 'modelscope']:
        if model_loaded:
            break
            
        try:
            print(f"\nğŸ”„ å°è¯•ä» {source_name.upper()} åŠ è½½æ¨¡å‹...")
            model_path = MODEL_SOURCES[source_name]
            
            model, tokenizer = load_model_from_source(
                source_name=source_name,
                model_path=model_path,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            
            # è®¾ç½® pad token
            if getattr(tokenizer, "pad_token_id", None) is None and getattr(tokenizer, "eos_token_id", None) is not None:
                tokenizer.pad_token = tokenizer.eos_token
            if getattr(model.config, "pad_token_id", None) is None and getattr(tokenizer, "pad_token_id", None) is not None:
                model.config.pad_token_id = tokenizer.pad_token_id
            
            print(f"âœ… æ¨¡å‹ä» {source_name.upper()} åŠ è½½æˆåŠŸï¼")
            print("="*50)
            model_loaded = True
            MODEL_SOURCE = source_name  # è®°å½•ä½¿ç”¨çš„æ¨¡å‹æº
            
        except (ModelLoadTimeoutError, Exception) as e:
            error_type = type(e).__name__
            if isinstance(e, ModelLoadTimeoutError) or 'timeout' in str(e).lower() or 'connection' in str(e).lower():
                print(f"â±ï¸ {source_name.upper()} åŠ è½½è¶…æ—¶/ç½‘ç»œé”™è¯¯: {e}")
            else:
                print(f"âŒ {source_name.upper()} åŠ è½½å¤±è´¥ ({error_type}): {e}")
            
            last_error = e
            if source_name == 'huggingface':
                print("ğŸ”„ HuggingFace åŠ è½½å¤±è´¥ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ° ModelScope...")
                print("   è¿™é€šå¸¸æ˜¯å› ä¸ºç½‘ç»œæ— æ³•è®¿é—® HuggingFace")
                time.sleep(2)  # çŸ­æš‚ç­‰å¾…
            continue
    
    if not model_loaded:
        error_msg = f"æ‰€æœ‰æ¨¡å‹æºåŠ è½½å¤±è´¥ã€‚æœ€åé”™è¯¯: {last_error}"
        print(f"âŒ {error_msg}")
        raise RuntimeError(error_msg)
    
    yield
    
    print("ğŸ›‘ æœåŠ¡å…³é—­ä¸­...")

# FastAPI åº”ç”¨
app = FastAPI(
    title="DeepSeek-OCR API - å¢å¼ºç‰ˆ",
    description="æ™ºèƒ½ OCR è¯†åˆ«æœåŠ¡ Â· Find & Freeform æ”¯æŒ",
    version="3.0.0",
    lifespan=lifespan
)

# CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

def build_prompt(
    mode: str,
    custom_prompt: str = "",
    find_term: str = "",
    grounding: bool = False
) -> str:
    """æ„å»ºæç¤ºè¯"""
    
    # æ¨¡å¼æ˜ å°„
    prompt_templates = {
        "document": "<image>\n<|grounding|>Convert the document to markdown.",
        "ocr": "<image>\n<|grounding|>OCR this image.",
        "free": "<image>\nFree OCR. Only output the raw text.",
        "figure": "<image>\nParse the figure.",
        "describe": "<image>\nDescribe this image in detail.",
        "find": "<image>\n<|grounding|>Locate <|ref|>{term}<|/ref|> in the image.",
        "freeform": "<image>\n{prompt}",
    }
    
    # æ„å»ºæœ€ç»ˆ prompt
    if mode == "find":
        term = find_term.strip() or "Total"
        prompt = prompt_templates["find"].replace("{term}", term)
    elif mode == "freeform":
        user_prompt = custom_prompt.strip() or "OCR this image."
        prompt = prompt_templates["freeform"].replace("{prompt}", user_prompt)
    else:
        prompt = prompt_templates.get(mode, prompt_templates["document"])
    
    return prompt

def clean_grounding_text(text: str) -> str:
    """ç§»é™¤ grounding æ ‡è®°"""
    cleaned = re.sub(
        r"<\|ref\|>(.*?)<\|/ref\|>\s*<\|det\|>\s*\[.*?\]\s*<\|/det\|>",
        r"\1",
        text,
        flags=re.DOTALL,
    )
    cleaned = re.sub(r"<\|grounding\|>", "", cleaned)
    return cleaned.strip()

def parse_detections(text: str, image_width: int, image_height: int) -> List[Dict[str, Any]]:
    """è§£æè¾¹ç•Œæ¡†åæ ‡"""
    boxes = []
    
    DET_BLOCK = re.compile(
        r"<\|ref\|>(?P<label>.*?)<\|/ref\|>\s*<\|det\|>\s*(?P<coords>\[.*?\])\s*<\|/det\|>",
        re.DOTALL,
    )
    
    for m in DET_BLOCK.finditer(text or ""):
        label = m.group("label").strip()
        coords_str = m.group("coords").strip()
        
        try:
            import ast
            parsed = ast.literal_eval(coords_str)
            
            # æ ‡å‡†åŒ–ä¸ºåˆ—è¡¨çš„åˆ—è¡¨
            if isinstance(parsed, list) and len(parsed) == 4 and all(isinstance(n, (int, float)) for n in parsed):
                box_coords = [parsed]
            elif isinstance(parsed, list):
                box_coords = parsed
            else:
                continue
            
            # å¤„ç†æ¯ä¸ª box
            for box in box_coords:
                if isinstance(box, (list, tuple)) and len(box) >= 4:
                    # ä» 0-999 å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºå®é™…åƒç´ åæ ‡
                    x1 = int(float(box[0]) / 999 * image_width)
                    y1 = int(float(box[1]) / 999 * image_height)
                    x2 = int(float(box[2]) / 999 * image_width)
                    y2 = int(float(box[3]) / 999 * image_height)
                    boxes.append({"label": label, "box": [x1, y1, x2, y2]})
        except Exception as e:
            print(f"âŒ è§£æåæ ‡å¤±è´¥: {e}")
            continue
    
    return boxes

@app.get("/", response_class=HTMLResponse)
async def root():
    """è¿”å› Web UI"""
    ui_file_path = Path(__file__).parent / "ocr_ui_modern.html"
    
    if ui_file_path.exists():
        with open(ui_file_path, 'r', encoding='utf-8') as f:
            return HTMLResponse(content=f.read())
    
    return HTMLResponse(content="<h1>DeepSeek-OCR Web UI</h1><p>UI file not found</p>")

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "model": MODEL_PATH,
        "model_source": MODEL_SOURCE or "unknown",
        "engine": "transformers",
        "model_loaded": model is not None,
        "gpu_available": torch.cuda.is_available(),
        "gpu_count": torch.cuda.device_count() if torch.cuda.is_available() else 0,
        "available_sources": list(MODEL_SOURCES.keys())
    }

@app.post("/ocr")
async def ocr_endpoint(
    file: UploadFile = File(...),
    prompt_type: str = Form("document"),
    find_term: str = Form(""),
    custom_prompt: str = Form(""),
    grounding: bool = Form(False)
):
    """OCR è¯†åˆ«æ¥å£ - å¢å¼ºç‰ˆæ”¯æŒ Find å’Œ Freeform"""
    
    if model is None or tokenizer is None:
        raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåŠ è½½")
    
    tmp_file = None
    output_dir = None
    
    try:
        # è¯»å–ä¸Šä¼ çš„å›¾ç‰‡æ•°æ®
        image_data = await file.read()
        
        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.png', mode='wb') as tmp:
            tmp.write(image_data)
            tmp_file = tmp.name
        
        print(f"ğŸ“¸ ä¸´æ—¶æ–‡ä»¶å·²ä¿å­˜: {tmp_file}")
        
        # è¯»å–å›¾ç‰‡è·å–å°ºå¯¸
        try:
            with Image.open(tmp_file) as img:
                img = ImageOps.exif_transpose(img)
                img = img.convert('RGB')
                orig_w, orig_h = img.size
                print(f"ğŸ“ å›¾ç‰‡å°ºå¯¸: {orig_w}x{orig_h}")
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"å›¾ç‰‡åŠ è½½å¤±è´¥: {str(e)}")
        
        # æ„å»º prompt
        prompt = build_prompt(prompt_type, custom_prompt, find_term, grounding)
        print(f"ğŸ’¬ æç¤ºè¯: {prompt[:100]}...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = tempfile.mkdtemp(prefix="ocr_")
        
        # æ‰§è¡Œæ¨ç†
        print(f"ğŸš€ å¼€å§‹æ¨ç†...")
        result = model.infer(
            tokenizer,
            prompt=prompt,
            image_file=tmp_file,
            output_path=output_dir,
            base_size=1024,
            image_size=640,
            crop_mode=True,
            save_results=False,
            test_compress=False,
            eval_mode=True,
        )
        
        print(f"âœ… æ¨ç†å®Œæˆï¼Œç»“æœç±»å‹: {type(result)}")
        
        # å¤„ç†ç»“æœ
        if isinstance(result, str):
            text = result.strip()
        elif isinstance(result, dict) and "text" in result:
            text = str(result["text"]).strip()
        else:
            text = str(result).strip()
        
        # å¦‚æœæ²¡æœ‰ç»“æœï¼Œæ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        if not text:
            result_file = os.path.join(output_dir, "result.mmd")
            if os.path.exists(result_file):
                with open(result_file, 'r', encoding='utf-8') as f:
                    text = f.read().strip()
        
        if not text:
            text = "æ¨¡å‹æœªè¿”å›ç»“æœ"
        
        print(f"ğŸ“ ç»“æœé•¿åº¦: {len(text)} å­—ç¬¦")
        
        # è§£æ grounding boxes
        boxes = []
        if "<|det|>" in text or "<|ref|>" in text:
            boxes = parse_detections(text, orig_w, orig_h)
            print(f"ğŸ“¦ æ‰¾åˆ° {len(boxes)} ä¸ªè¾¹ç•Œæ¡†")
        
        # æ¸…ç†æ˜¾ç¤ºæ–‡æœ¬
        display_text = clean_grounding_text(text)
        
        if not display_text and boxes:
            display_text = ", ".join([b["label"] for b in boxes])
        
        return JSONResponse({
            "success": True,
            "text": display_text,
            "raw_text": text,
            "boxes": boxes,
            "image_dims": {"w": orig_w, "h": orig_h},
            "prompt_type": prompt_type,
            "metadata": {
                "mode": prompt_type,
                "grounding": grounding or (prompt_type in ["find", "document", "ocr"]),
                "has_boxes": len(boxes) > 0,
                "engine": "transformers"
            }
        })
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"âŒ é”™è¯¯è¯¦æƒ…:\n{error_detail}")
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if tmp_file and os.path.exists(tmp_file):
            try:
                os.remove(tmp_file)
                print(f"ğŸ—‘ï¸ ä¸´æ—¶æ–‡ä»¶å·²åˆ é™¤: {tmp_file}")
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
        if output_dir and os.path.exists(output_dir):
            shutil.rmtree(output_dir, ignore_errors=True)
            print(f"ğŸ—‘ï¸ è¾“å‡ºç›®å½•å·²æ¸…ç†: {output_dir}")

def pdf_to_images(pdf_path: str, dpi: int = 144) -> List[Image.Image]:
    """
    å°† PDF è½¬æ¢ä¸ºå›¾ç‰‡åˆ—è¡¨
    ä½¿ç”¨ PyMuPDF (fitz) è¿›è¡Œé«˜è´¨é‡è½¬æ¢
    
    Args:
        pdf_path: PDF æ–‡ä»¶è·¯å¾„
        dpi: è¾“å‡ºåˆ†è¾¨ç‡ï¼Œé»˜è®¤ 144 DPIï¼ˆé«˜è´¨é‡ï¼‰
    
    Returns:
        å›¾ç‰‡åˆ—è¡¨ï¼Œæ¯é¡µä¸€ä¸ª PIL Image å¯¹è±¡
    """
    images = []
    pdf_document = None
    
    try:
        pdf_document = fitz.open(pdf_path)
        zoom = dpi / 72.0
        matrix = fitz.Matrix(zoom, zoom)
        
        for page_num in range(pdf_document.page_count):
            page = pdf_document[page_num]
            
            # å°†é¡µé¢æ¸²æŸ“ä¸ºåƒç´ å›¾
            pixmap = page.get_pixmap(matrix=matrix, alpha=False)
            
            # è½¬æ¢ä¸º PIL Image
            img_data = pixmap.tobytes("png")
            img = Image.open(io.BytesIO(img_data))
            
            # ç¡®ä¿æ˜¯ RGB æ¨¡å¼
            if img.mode in ('RGBA', 'LA'):
                background = Image.new('RGB', img.size, (255, 255, 255))
                background.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
                img = background
            elif img.mode != 'RGB':
                img = img.convert('RGB')
            
            images.append(img)
            print(f"ğŸ“„ PDF ç¬¬ {page_num + 1} é¡µå·²è½¬æ¢ä¸ºå›¾ç‰‡ ({img.size[0]}x{img.size[1]})")
        
        print(f"âœ… PDF è½¬æ¢å®Œæˆï¼Œå…± {len(images)} é¡µ")
        
    except Exception as e:
        print(f"âŒ PDF è½¬æ¢å¤±è´¥: {e}")
        raise HTTPException(status_code=400, detail=f"PDF è½¬æ¢å¤±è´¥: {str(e)}")
    finally:
        if pdf_document:
            pdf_document.close()
    
    return images

@app.post("/pdf-to-images")
async def pdf_to_images_endpoint(file: UploadFile = File(...)):
    """
    PDF è½¬å›¾ç‰‡æ¥å£
    æ¥æ”¶ PDF æ–‡ä»¶ï¼Œè¿”å›å¤šå¼ å›¾ç‰‡çš„ base64 ç¼–ç åˆ—è¡¨
    
    Returns:
        {
            "success": bool,
            "images": [{"data": "base64", "name": "page_1.png", "width": int, "height": int}, ...],
            "page_count": int,
            "original_filename": str
        }
    """
    tmp_file = None
    
    try:
        # éªŒè¯æ–‡ä»¶ç±»å‹
        if not file.filename.lower().endswith('.pdf'):
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å¿…é¡»æ˜¯ PDF æ ¼å¼")
        
        # è¯»å– PDF æ•°æ®
        pdf_data = await file.read()
        
        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf', mode='wb') as tmp:
            tmp.write(pdf_data)
            tmp_file = tmp.name
        
        print(f"ğŸ“„ PDF æ–‡ä»¶å·²ä¿å­˜: {tmp_file} (å¤§å°: {len(pdf_data)} å­—èŠ‚)")
        
        # å…ˆæ‰“å¼€PDFè·å–æ€»é¡µæ•°
        pdf_document = fitz.open(tmp_file)
        total_pages = pdf_document.page_count
        pdf_document.close()
        
        print(f"ğŸ“„ PDF æ–‡ä»¶æ€»é¡µæ•°: {total_pages}")
        
        # è½¬æ¢ PDF ä¸ºå›¾ç‰‡
        images = pdf_to_images(tmp_file, dpi=144)
        
        if not images:
            raise HTTPException(status_code=400, detail="PDF æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•è½¬æ¢")
        
        # è½¬æ¢ä¸º base64 ç¼–ç 
        image_list = []
        original_name = file.filename or "document.pdf"
        base_name = os.path.splitext(os.path.basename(original_name))[0]
        
        for idx, img in enumerate(images):
            # å°† PIL Image è½¬æ¢ä¸º PNG bytes
            img_buffer = io.BytesIO()
            img.save(img_buffer, format='PNG', optimize=True)
            img_bytes = img_buffer.getvalue()
            
            # è½¬æ¢ä¸º base64
            img_base64 = base64.b64encode(img_bytes).decode('utf-8')
            
            image_list.append({
                "data": f"data:image/png;base64,{img_base64}",
                "name": f"{base_name}_page_{idx + 1}.png",
                "width": img.size[0],
                "height": img.size[1],
                "page_number": idx + 1
            })
            
            print(f"âœ… å·²è½¬æ¢ç¬¬ {idx + 1}/{total_pages} é¡µ")
        
        print(f"âœ… æˆåŠŸè½¬æ¢ {len(image_list)} å¼ å›¾ç‰‡")
        
        return JSONResponse({
            "success": True,
            "images": image_list,
            "page_count": len(image_list),
            "total_pages": total_pages,
            "original_filename": original_name
        })
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"âŒ PDF è½¬å›¾ç‰‡é”™è¯¯:\n{error_detail}")
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if tmp_file and os.path.exists(tmp_file):
            try:
                os.remove(tmp_file)
                print(f"ğŸ—‘ï¸ ä¸´æ—¶ PDF æ–‡ä»¶å·²åˆ é™¤: {tmp_file}")
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

if __name__ == "__main__":
    import sys
    
    port = 8001
    if len(sys.argv) > 1:
        try:
            port = int(sys.argv[1])
        except:
            port = 8001
    
    print("\n" + "="*50)
    print("ğŸš€ DeepSeek-OCR å¢å¼ºç‰ˆ Web æœåŠ¡")
    print("="*50)
    print(f"ğŸ“ è®¿é—®åœ°å€: http://0.0.0.0:{port}")
    print(f"ğŸ“š API æ–‡æ¡£: http://0.0.0.0:{port}/docs")
    print(f"â¤ï¸ å¥åº·æ£€æŸ¥: http://0.0.0.0:{port}/health")
    print("="*50 + "\n")
    
    uvicorn.run(app, host="0.0.0.0", port=port, log_level="info")
